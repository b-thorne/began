{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard with custom training schedule\n",
    "\n",
    "The API for `tf.keras.callbacks.TensorBoard` is developed for use with the `Model.fit` method. However, since we have a complicated training step for the GAN, we have to use the `TensorBoard` callback as a normal function, and pass it the values of the losses and images that we want to record.\n",
    "\n",
    "Let's take the example of the MNIST training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from pathlib import Path\n",
    "import os\n",
    "import began\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_G (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "Reshape (Reshape)            (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "BNorm_G1 (BatchNormalization (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "LRelu_G1 (LeakyReLU)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "UpSample_1 (UpSampling2D)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G1 (Conv2D)           (None, 8, 8, 32)          51232     \n",
      "_________________________________________________________________\n",
      "BN_G2 (BatchNormalization)   (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "LRelu_G2 (LeakyReLU)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "UpSample_2 (UpSampling2D)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G2 (Conv2D)           (None, 16, 16, 16)        12816     \n",
      "_________________________________________________________________\n",
      "BN_G3 (BatchNormalization)   (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "LRelu_G3 (LeakyReLU)         (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "UpSample_3 (UpSampling2D)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G3 (Conv2D)           (None, 32, 32, 1)         401       \n",
      "_________________________________________________________________\n",
      "Tanh (Activation)            (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Crop2D (Cropping2D)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 98,689\n",
      "Trainable params: 98,465\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Project directory\n",
    "PROJ_DIR = Path(\"/home/bthorne/projects/gan/began\")\n",
    "# Model directory\n",
    "MODEL_PATH = PROJ_DIR / \"model\" / \"mnist_dcgan_NTRAIN5000.h5\"\n",
    "\n",
    "# Network architecture\n",
    "DEPTH = 16\n",
    "IMG_DIM = 28\n",
    "CHANNELS = 1\n",
    "KERNELS = [5, 5, 5]\n",
    "STRIDES = [2, 2, 2]\n",
    "FILTERS = [DEPTH * 2 ** i for i in range(len(KERNELS))]\n",
    "LATENT_DIM = 32\n",
    "\n",
    "# Derived parameters\n",
    "SHAPE = (IMG_DIM, IMG_DIM, CHANNELS)\n",
    "\n",
    "# Training parameters\n",
    "TRAIN_STEPS = 5000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Build inidividual and joint models.\n",
    "DIS = began.dcgan.build_discriminator(FILTERS, KERNELS, STRIDES, SHAPE)\n",
    "GEN = began.dcgan.build_generator(DIS, FILTERS, KERNELS, STRIDES, LATENT_DIM, SHAPE)\n",
    "ADV = began.dcgan.build_adversarial_model(DIS, GEN)\n",
    "print(GEN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw training data\n",
    "(X_TRAIN, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Apply preprocessing to scale data\n",
    "X_TRAIN = X_TRAIN[..., None] / 255. * 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 00000, dloss 0.921\n",
      "Step 00010, dloss 0.214\n",
      "Step 00020, dloss 0.150\n",
      "Step 00030, dloss 0.495\n",
      "Step 00040, dloss 0.528\n",
      "Step 00050, dloss 0.367\n",
      "Step 00060, dloss 0.333\n",
      "Step 00070, dloss 0.245\n",
      "Step 00080, dloss 0.207\n",
      "Step 00090, dloss 0.156\n",
      "Step 00100, dloss 0.274\n",
      "Step 00110, dloss 0.161\n",
      "Step 00120, dloss 0.106\n",
      "Step 00130, dloss 0.111\n",
      "Step 00140, dloss 0.105\n",
      "Step 00150, dloss 0.103\n",
      "Step 00160, dloss 0.121\n",
      "Step 00170, dloss 0.084\n",
      "Step 00180, dloss 0.040\n",
      "Step 00190, dloss 0.085\n",
      "Step 00200, dloss 0.052\n",
      "Step 00210, dloss 0.116\n",
      "Step 00220, dloss 0.058\n",
      "Step 00230, dloss 0.149\n",
      "Step 00240, dloss 0.095\n",
      "Step 00250, dloss 0.079\n",
      "Step 00260, dloss 0.169\n",
      "Step 00270, dloss 0.086\n",
      "Step 00280, dloss 0.041\n",
      "Step 00290, dloss 0.130\n",
      "Step 00300, dloss 0.026\n",
      "Step 00310, dloss 0.084\n",
      "Step 00320, dloss 0.033\n",
      "Step 00330, dloss 0.035\n",
      "Step 00340, dloss 0.022\n",
      "Step 00350, dloss 0.019\n",
      "Step 00360, dloss 0.022\n",
      "Step 00370, dloss 0.092\n",
      "Step 00380, dloss 0.018\n",
      "Step 00390, dloss 0.009\n",
      "Step 00400, dloss 0.015\n",
      "Step 00410, dloss 0.025\n",
      "Step 00420, dloss 0.021\n",
      "Step 00430, dloss 0.015\n",
      "Step 00440, dloss 0.021\n",
      "Step 00450, dloss 0.092\n",
      "Step 00460, dloss 0.061\n",
      "Step 00470, dloss 0.012\n",
      "Step 00480, dloss 0.161\n",
      "Step 00490, dloss 0.143\n",
      "Step 00500, dloss 0.085\n",
      "Step 00510, dloss 0.110\n",
      "Step 00520, dloss 0.022\n",
      "Step 00530, dloss 0.058\n",
      "Step 00540, dloss 0.015\n",
      "Step 00550, dloss 0.157\n",
      "Step 00560, dloss 0.066\n",
      "Step 00570, dloss 0.224\n",
      "Step 00580, dloss 0.064\n",
      "Step 00590, dloss 0.010\n",
      "Step 00600, dloss 0.015\n",
      "Step 00610, dloss 0.084\n",
      "Step 00620, dloss 0.019\n",
      "Step 00630, dloss 0.010\n",
      "Step 00640, dloss 0.115\n",
      "Step 00650, dloss 0.006\n",
      "Step 00660, dloss 0.056\n",
      "Step 00670, dloss 0.182\n",
      "Step 00680, dloss 0.010\n",
      "Step 00690, dloss 0.012\n",
      "Step 00700, dloss 0.011\n",
      "Step 00710, dloss 0.060\n",
      "Step 00720, dloss 0.098\n",
      "Step 00730, dloss 0.011\n",
      "Step 00740, dloss 0.012\n",
      "Step 00750, dloss 0.010\n",
      "Step 00760, dloss 0.085\n",
      "Step 00770, dloss 0.004\n",
      "Step 00780, dloss 0.007\n",
      "Step 00790, dloss 0.007\n",
      "Step 00800, dloss 0.076\n",
      "Step 00810, dloss 0.280\n",
      "Step 00820, dloss 0.070\n",
      "Step 00830, dloss 0.004\n",
      "Step 00840, dloss 0.088\n",
      "Step 00850, dloss 0.017\n",
      "Step 00860, dloss 0.020\n",
      "Step 00870, dloss 0.079\n",
      "Step 00880, dloss 0.009\n",
      "Step 00890, dloss 0.076\n",
      "Step 00900, dloss 0.088\n",
      "Step 00910, dloss 0.011\n",
      "Step 00920, dloss 0.004\n",
      "Step 00930, dloss 0.072\n",
      "Step 00940, dloss 0.011\n",
      "Step 00950, dloss 0.263\n",
      "Step 00960, dloss 0.007\n",
      "Step 00970, dloss 0.006\n",
      "Step 00980, dloss 0.089\n",
      "Step 00990, dloss 0.018\n",
      "Step 01000, dloss 0.238\n",
      "Step 01010, dloss 0.013\n",
      "Step 01020, dloss 0.007\n",
      "Step 01030, dloss 0.008\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tboard_callback.set_model(DIS)\n",
    "\n",
    "image_lat = np.random.randn(1, LATENT_DIM)\n",
    "for step in range(TRAIN_STEPS):\n",
    "        tf.summary.experimental.set_step(step)\n",
    "        # First train the discriminator with correct labels\n",
    "        # Randomly select batch from training samples\n",
    "        y_real = np.random.binomial(1, 0.99, size=[BATCH_SIZE, 1])\n",
    "        y_fake = np.random.binomial(1, 0.01, size=[BATCH_SIZE, 1])\n",
    "        idx = np.random.randint(0, X_TRAIN.shape[0], size=BATCH_SIZE)\n",
    "        \n",
    "        # Rotate each image by random integer multiples of 90 degrees. This should\n",
    "        # probably be transfereed out of this code to be done in the data preparation\n",
    "        # stage. \n",
    "        images_real = X_TRAIN[idx, ...]\n",
    "        images_real = np.array([np.rot90(im, np.random.randint(0, 4)) for im in images_real])\n",
    "\n",
    "        # Use `generator` to create fake images.\n",
    "        noise = np.random.normal(loc=0., scale=1., size=[BATCH_SIZE, LATENT_DIM])\n",
    "        images_fake = GEN.predict(noise)\n",
    "\n",
    "        # Train the discriminator on real and fake images.\n",
    "        dloss_real = DIS.train_on_batch(images_real, y_real)\n",
    "        dloss_fake = DIS.train_on_batch(images_fake, y_fake)\n",
    "        dloss = 0.5 * (dloss_real + dloss_fake)\n",
    "        # Now train the adversarial network.\n",
    "        # Create new fake images, and label as if they are from the training set.\n",
    "        # Lie indicates that we are tricking the adversarial network by\n",
    "        # telling it the target is valid, when in reality the discriminator\n",
    "        # is being fed fake images by the generator.\n",
    "        y_lie = np.ones([BATCH_SIZE, 1])\n",
    "        noise = np.random.normal(loc=0., scale=1., size=[BATCH_SIZE, LATENT_DIM])\n",
    "        a_loss = ADV.train_on_batch(noise, y_lie)\n",
    "        tf.summary.image('random_draw', GEN.predict(image_lat))\n",
    "        tf.summary.scalar('aloss', a_loss)\n",
    "        tf.summary.scalar('dloss', dloss)\n",
    "        #tboard_callback.on_train_batch_end(batch=step)\n",
    "        if not step % 10:\n",
    "            print(\"Step {:05d}, dloss {:.03f}\".format(step, dloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ADV.get_layer('Generator').predict(np.random.randn(1, 16))[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save(os.fspath(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
